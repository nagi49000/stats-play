{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e060decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import statsmodels.stats.gof\n",
    "import statsmodels.api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af2431b",
   "metadata": {},
   "source": [
    "# Chi-squared categorical\n",
    "\n",
    "This notebook presents some simple examples of a chi-squared test on categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ab321",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Wikipedia's article on the [chi-squared test](https://en.wikipedia.org/wiki/Chi-squared_test) gives an overview , referencing the [chi-squared distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution) of $k$ degrees of freedom; $\\chi^2_k \\sim \\sum_{i=1}^k Z^2_i$, where the $Z_i$ are independent, and $Z_i \\sim N(0,1)$.\n",
    "\n",
    "The typical form of a chi-squared test is a [Pearson's chi-squred test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test). The degrees of freedom depends on the type of test, which may be a test of \n",
    "- goodness-of-fit\n",
    "- homogeneity\n",
    "- independence\n",
    "\n",
    "For a population split into categories, the null hypothesis for (Pearson's) chi-squared test is that the there are no differences between the categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11266a6b",
   "metadata": {},
   "source": [
    "## Simple example\n",
    "Consider 2 clothing stores, Primark, Next and Debenhams. They all sell shirts.\n",
    "\n",
    "Does a particular store significantly sell more shirts than another? The null hypothesis becomes that the number of each store's shirts comes from the same distribution.\n",
    "\n",
    "### When the categories are all similar\n",
    "Visiting a canididate stores on the high street, one can count the number of shirts in the stores. This might yield the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c78b6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           shirts\n",
      "Debenhams      32\n",
      "Next           27\n",
      "Primark        28\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"shirts\": {\"Primark\": 28, \"Debenhams\": 32, \"Next\": 27}})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4cec1",
   "metadata": {},
   "source": [
    "where the number of blue shirts is always roughly twice the number of red shirts. There are 3 stores, and $28 + 27 + 32 = 87$ shirts in total, yielding an expected number of 29 shirts per store. One can then go ahead and calculate a $\\chi^2$ test statistic\n",
    "\n",
    "$\\chi^2 = \\sum_i \\frac{(O_i - E_i)^2}{E_i}$\n",
    "\n",
    "which superficially, looks like a sum of variables $\\frac{(x-\\mu)^2}{\\sigma}$. In the limit of the number of test samples going to infinity, the test statistic approaches a true chi-squared distribution. In this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6cbed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi squared test stat = 0.4827586206896552\n"
     ]
    }
   ],
   "source": [
    "e_i = np.mean(df[\"shirts\"])\n",
    "chi_2 = np.sum((df[\"shirts\"].array - e_i) ** 2 / e_i)\n",
    "print(f\"chi squared test stat = {chi_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b462343",
   "metadata": {},
   "source": [
    "There are 3 cells, and the calculation is made on differences, so the degrees of freedom is 3 - 1 = 2. This allows calculation of a one-sided p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b2fc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value = 0.7855436050549208\n"
     ]
    }
   ],
   "source": [
    "p_value = 1.0 - scipy.stats.chi2.cdf(chi_2, 2)\n",
    "print(f\"P-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6961e",
   "metadata": {},
   "source": [
    "So the probability of getting a result more extreme than the test statistic is 0.786. At an reasonable significance level, (e.g. 5% or 10%), this would lead to accepting the null hypothesis that the categories are all statistically similar. \n",
    "\n",
    "### When the categories are dis-similar\n",
    "\n",
    "Consider now a heavily imbalanced class case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d35dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           shirts\n",
      "Debenhams      21\n",
      "Next           46\n",
      "Primark        20\n",
      "chi squared test stat = 14.96551724137931\n",
      "P-value = 0.000562702988414987\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"shirts\": {\"Primark\": 20, \"Debenhams\": 21, \"Next\": 46}})\n",
    "print(df)\n",
    "e_i = np.mean(df[\"shirts\"])\n",
    "chi_2 = np.sum((df[\"shirts\"].array - e_i) ** 2 / e_i)\n",
    "print(f\"chi squared test stat = {chi_2}\")\n",
    "p_value = 1.0 - scipy.stats.chi2.cdf(chi_2, 2)\n",
    "print(f\"P-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38cac3d",
   "metadata": {},
   "source": [
    "Thus the probability of getting a more extreme example is 0.0006. At a reasonable significance level, e.g. 5%, this would lead to a rejection of the null hypothesis, and one would conclude that the categories are different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275b295",
   "metadata": {},
   "source": [
    "### Calculation using libs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c6498e",
   "metadata": {},
   "source": [
    "Scipy has a chisquare routine, where one can pass in the raw data to obtain the test statistic and p-value. The routine accepts an argument ddof, which affects the $k$ value used by the test. By default, k will be the length of the input array (call it N) minus 1. With a ddof argument, this becomes $k = N - 1 - \\textrm{ddof}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62f3210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=14.96551724137931, pvalue=0.0005627029884150075)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.chisquare(df[\"shirts\"], ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a74ed4",
   "metadata": {},
   "source": [
    "These numbers can also be obtained with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e22e25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.96551724137931, 0.0005627029884150075)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsmodels.stats.gof.chisquare(df[\"shirts\"], ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c211c",
   "metadata": {},
   "source": [
    "## Multiple categories or sample sets - homogeneity/independence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef348de4",
   "metadata": {},
   "source": [
    "Consider the case where now each of the stores sells multiple apparel, e.g. vests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede158fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           shirts  vests\n",
      "Primark        28     61\n",
      "Debenhams      32     62\n",
      "Next           27     57\n",
      "           shirts  vests  Total\n",
      "Primark        28     61     89\n",
      "Debenhams      32     62     94\n",
      "Next           27     57     84\n",
      "Total          87    180    267\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"shirts\": {\"Primark\": 28, \"Debenhams\": 32, \"Next\": 27}, \"vests\": {\"Primark\": 61, \"Debenhams\": 62, \"Next\": 57}})\n",
    "df_totals = df.copy()\n",
    "df_totals.loc['Total']= df_totals.sum(numeric_only=True, axis=0)\n",
    "df_totals.loc[:,'Total'] = df_totals.sum(numeric_only=True, axis=1)\n",
    "print(df)\n",
    "print(df_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a2bed",
   "metadata": {},
   "source": [
    "The totals can be used to get the 'expected' number of elements in each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7568517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of Primark shirts = 29.0\n",
      "Expected number of Primark vests = 60.0\n"
     ]
    }
   ],
   "source": [
    "def get_expected(df_tots, row_id, column_id):\n",
    "    return df_tots.loc[row_id, \"Total\"] * df_tots.loc[\"Total\", column_id] / df_tots.loc[\"Total\", \"Total\"]\n",
    "print(f\"Expected number of Primark shirts = {get_expected(df_totals, 'Primark', 'shirts')}\")\n",
    "print(f\"Expected number of Primark vests = {get_expected(df_totals, 'Primark', 'vests')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43b039",
   "metadata": {},
   "source": [
    "This allows a calculation of a chi-squared test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d776fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi squared test stat = 0.14960040876218433\n"
     ]
    }
   ],
   "source": [
    "chi_2 = 0.0\n",
    "for row_id in df.index:\n",
    "    for col_id in df.columns:\n",
    "        o_i = df.loc[row_id, col_id]\n",
    "        e_i = get_expected(df_totals, row_id, col_id)\n",
    "        chi_2 += (o_i - e_i) ** 2 / e_i\n",
    "print(f\"chi squared test stat = {chi_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc829e16",
   "metadata": {},
   "source": [
    "For tabular data, since the calculation comes down to differences, the number of degrees of freedom are (number of rows -1) x (number of columns - 1) = (3-1) x (2-1) = 2. This allows calculation of a p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9af71cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value = 0.9279288639307913\n"
     ]
    }
   ],
   "source": [
    "p_value = 1.0 - scipy.stats.chi2.cdf(chi_2, 2)\n",
    "print(f\"P-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098d0ae",
   "metadata": {},
   "source": [
    "Thus the probability of getting a more extreme example is 0.928. So far this is all calculation. Consider, now, the hypothesis test questions that can be posed. The data has 2 parameters, so the variety of questions is larger.\n",
    "\n",
    "There is a question of 'independence' of store. In this case, the null hypothesis would be that the apparel population is independent of store.\n",
    "\n",
    "There is also a question (which is related, but not necessarily the same) of 'homogeneity'. In this case, the null hypothesis would be that the distribution of shirts and vests is the same amongst all stores.\n",
    "\n",
    "In both cases, the calculation is the same. At an reasonable significance level, (e.g. 5% or 10%), in both cases, this would lead to accepting the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc2b1b6",
   "metadata": {},
   "source": [
    "### Calculation using libs\n",
    "\n",
    "[scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) can be used to perform the calculation, returning a 4-tuple of (test stat, p-value, degrees of freedom, expected values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74fee3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14960040876218433,\n",
       " 0.9279288639307913,\n",
       " 2,\n",
       " array([[29.        , 60.        ],\n",
       "        [30.62921348, 63.37078652],\n",
       "        [27.37078652, 56.62921348]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.chi2_contingency(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430a023",
   "metadata": {},
   "source": [
    "[Contingency tables](https://www.statsmodels.org/dev/contingency_tables.html) in statsmodels can be useful for seeing the contributions to the test statistic (each element being the respective value for $\\frac{(O_i - E_i)^2}{E_i}$). The sum of the contributions retrieves the test statistic (which can be handy for seeing the entry that contribute heavily to breaking homogeneity/independence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "529e0b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shirts</th>\n",
       "      <th>vests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Primark</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debenhams</th>\n",
       "      <td>0.061348</td>\n",
       "      <td>0.029652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Next</th>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             shirts     vests\n",
       "Primark    0.034483  0.016667\n",
       "Debenhams  0.061348  0.029652\n",
       "Next       0.005023  0.002428"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = statsmodels.api.stats.Table(df)\n",
    "table.chi2_contribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f9dd41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi squared test stat = 0.14960040876218433\n"
     ]
    }
   ],
   "source": [
    "chi2 = table.chi2_contribs.to_numpy().sum()\n",
    "print(f\"chi squared test stat = {chi_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f0c18",
   "metadata": {},
   "source": [
    "## Goodness of fit\n",
    "\n",
    "Consider the case now where a distributor knows how many shirts should be in the local stores, i.e. there is a predefined distribution. How close is the observation to the distributor's knowledge? The null hypothesis is that the observed distribution is sampled from the the predefined distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8c0951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           shirts  expected_shirts\n",
      "Primark        28               30\n",
      "Debenhams      32               35\n",
      "Next           27               30\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"shirts\": {\"Primark\": 28, \"Debenhams\": 32, \"Next\": 27}, \n",
    "                   \"expected_shirts\": {\"Primark\": 30, \"Debenhams\": 35, \"Next\": 30}})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573cc143",
   "metadata": {},
   "source": [
    "This can be framed as a chi-squared test, where the null hypothesis is that the observed distribution is a \"good fit\" to the expected distribution.\n",
    "\n",
    "To do this, the two distributions need to be normalised (i.e. sum to the same number, so that they can be treated as distributions over the same space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "721a0bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           shirts  expected_shirts  expected_shirts_normed\n",
      "Primark        28               30               27.473684\n",
      "Debenhams      32               35               32.052632\n",
      "Next           27               30               27.473684\n"
     ]
    }
   ],
   "source": [
    "df[\"expected_shirts_normed\"] = df[\"expected_shirts\"] * df[\"shirts\"].sum() / df[\"expected_shirts\"].sum()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e04075",
   "metadata": {},
   "source": [
    "This is a slightly different calculation from before, since now all the $E_i$ have been supplied. The test statistic now becomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33caa50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi squared test stat = 0.018336070060208\n"
     ]
    }
   ],
   "source": [
    "chi_2 = np.sum((df[\"shirts\"] - df[\"expected_shirts_normed\"]) ** 2 / df[\"expected_shirts_normed\"])\n",
    "print(f\"chi squared test stat = {chi_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e04f782",
   "metadata": {},
   "source": [
    "The degrees of freedom $k$ are given by $k = n - 1 - q$, where $n$ is the number of non-empty cells (3 in this case) and $p$ is the number of parameters in the model (e.g. for a 1D line of best fit, $y=mx+c$, this would have $q=2$). In this case, since no free parameters specify the fit, $q=0$. This means that a p-value is calculable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d2587fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value = 0.9908738632636134\n"
     ]
    }
   ],
   "source": [
    "p_value = 1.0 - scipy.stats.chi2.cdf(chi_2, 3-1)\n",
    "print(f\"P-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d33b2",
   "metadata": {},
   "source": [
    "There is a 0.991 probability of an observation being more extreme than the observed observation, which for any reasonable significance level would mean accepting the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34fe70",
   "metadata": {},
   "source": [
    "### Calculation using libs\n",
    "\n",
    "The scipy and statsmodel examples in the simple example above have keywords that allow supplying an expected distribution. Since the degrees of freedom within the functions are calculated as $k = n- 1 - \\textrm{ddof}$, the number of prarameters in the model, $q$ can be supplied as ddof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80ae4df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=0.018336070060208, pvalue=0.9908738632636134)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.chisquare(df[\"shirts\"], f_exp=df[\"expected_shirts_normed\"], ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f926044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.018336070060208, 0.9908738632636134)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsmodels.stats.gof.chisquare(df[\"shirts\"], f_exp=df[\"expected_shirts_normed\"], ddof=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
